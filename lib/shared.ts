export const AIModelOptions = [
  {
    id: 1,
    name: 'Deepseek: R1 0528',
    description: 'May 28th update to the original DeepSeek R1',
    model: 'deepseek/deepseek-r1-0528:free',
  },
  {
    id: 2,
    name: 'Qwen3 32B',
    description:
      'Qwen3-32B is a dense 32.8B parameter causal language model from the Qwen3 series',
    model: 'qwen/qwen3-32b:free',
  },
  {
    id: 3,
    name: 'Llama 4 Maverick',
    description:
      'Llama 4 Maverick 17B Instruct (128E) is a high-capacity multimodal language model from Meta',
    model: 'meta-llama/llama-4-maverick:free',
  },
  {
    id: 4,
    name: 'Llama 4 Scout',
    description:
      'Llama 4 Scout 17B Instruct (16E) is a mixture-of-experts (MoE) language model developed by Meta',
    model: 'meta-llama/llama-4-scout:free',
  },
  {
    id: 5,
    name: 'Mistral Small 3.1 24B',
    description:
      'Mistral Small 3.1 24B Instruct is an upgraded variant of Mistral Small 3 (2501)',
    model: 'mistralai/mistral-small-3.1-24b-instruct:free',
  },
  {
    id: 6,
    name: 'Gemini 2.0 Flash Experimental',
    description:
      'Gemini Flash 2.0 offers a significantly faster time to first token (TTFT) compared to Gemini Flash 1.5',
    model: 'google/gemini-2.0-flash-exp:free',
  },
  {
    id: 7,
    name: 'Microsoft: Phi 4',
    description:
      'Phi-4-reasoning is a 14B parameter dense decoder-only transformer developed by Microsoft.',
    model: 'microsoft/phi-4-reasoning:free',
  },
]
